2017.7.16 第一次用Git提交信息

基于kinect2.0的人机交互模式

一、动作识别两类：
        依据：识别各人体关节，但只能到手掌和 拇指，身体细节没法识别
        肢体语言识别：各关节相对位置关系，如挥手、摇头等
        手势识别：两种可能：直接识别手指间的位置关系或者使用编译好的样本库做对比，也可能要自己做样本

二、表情识别：过程依次是：
         1、人脸识别
         2、五官状态识别
         3、表情识别

三、语音识别：
         声源定位：角度和置信度，距离?
         语音识别：识别固定语句
         难度：数据格式不一样，资料少，分析处理有困难，需要看相关文献，周期有点长

四、场景深度信息：正在考虑怎么使用

